{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVF7xfL3RoJ8"
   },
   "source": [
    "# BERT\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**IMDB Dataset (pt_br)** \n",
    "\n",
    "Dataset com avaliações de filmes em português. Usado para classificação binária de sentimentos: positivo ou negativo.\n",
    "\n",
    "https://www.kaggle.com/datasets/luisfredgs/imdb-ptbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sa7z-GBOsBaa"
   },
   "outputs": [],
   "source": [
    "caminho = 'imdb-ptbr.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lN1fHsyjgGkr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 5052,
     "status": "ok",
     "timestamp": 1680116187474,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "nKKZshNir1Vl",
    "outputId": "ec624839-780f-40bb-ab5f-c4697f6113d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49454</th>\n",
       "      <td>49456</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49455</th>\n",
       "      <td>49457</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>49458</td>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>49459</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>49460</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49459 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            text_en  \\\n",
       "0          1  Once again Mr. Costner has dragged out a movie...   \n",
       "1          2  This is an example of why the majority of acti...   \n",
       "2          3  First of all I hate those moronic rappers, who...   \n",
       "3          4  Not even the Beatles could write songs everyon...   \n",
       "4          5  Brass pictures movies is not a fitting word fo...   \n",
       "...      ...                                                ...   \n",
       "49454  49456  Seeing as the vote average was pretty low, and...   \n",
       "49455  49457  The plot had some wretched, unbelievable twist...   \n",
       "49456  49458  I am amazed at how this movieand most others h...   \n",
       "49457  49459  A Christmas Together actually came before my t...   \n",
       "49458  49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                 text_pt sentiment  \n",
       "0      Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1      Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2      Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3      Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4      Filmes de fotos de latão não é uma palavra apr...       neg  \n",
       "...                                                  ...       ...  \n",
       "49454  Como a média de votos era muito baixa, e o fat...       pos  \n",
       "49455  O enredo teve algumas reviravoltas infelizes e...       pos  \n",
       "49456  Estou espantado com a forma como este filme e ...       pos  \n",
       "49457  A Christmas Together realmente veio antes do m...       pos  \n",
       "49458  O drama romântico da classe trabalhadora do di...       pos  \n",
       "\n",
       "[49459 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(caminho)\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1680116187476,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "xG1fCSxdt1dL",
    "outputId": "3c6434e6-1337-4f41-ecb2-58d9bdf5075d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    24765\n",
       "pos    24694\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1680116251959,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "YzIU_2iQuOuU",
    "outputId": "16b71ceb-73a1-4f2e-d3a6-af44823c5d74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0, 'pos': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df_data['sentiment'].unique()\n",
    "\n",
    "label_dict = {}\n",
    "\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NsoG4wMxueK0"
   },
   "outputs": [],
   "source": [
    "df_data['label'] = df_data['sentiment'].replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1680116358782,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "v40yC7bjvOKS",
    "outputId": "5672c179-87d6-4c12-f0a0-7627a3c198b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49454</th>\n",
       "      <td>49456</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49455</th>\n",
       "      <td>49457</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>49458</td>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>49459</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>49460</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49459 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            text_en  \\\n",
       "0          1  Once again Mr. Costner has dragged out a movie...   \n",
       "1          2  This is an example of why the majority of acti...   \n",
       "2          3  First of all I hate those moronic rappers, who...   \n",
       "3          4  Not even the Beatles could write songs everyon...   \n",
       "4          5  Brass pictures movies is not a fitting word fo...   \n",
       "...      ...                                                ...   \n",
       "49454  49456  Seeing as the vote average was pretty low, and...   \n",
       "49455  49457  The plot had some wretched, unbelievable twist...   \n",
       "49456  49458  I am amazed at how this movieand most others h...   \n",
       "49457  49459  A Christmas Together actually came before my t...   \n",
       "49458  49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                 text_pt sentiment  label  \n",
       "0      Mais uma vez, o Sr. Costner arrumou um filme p...       neg      0  \n",
       "1      Este é um exemplo do motivo pelo qual a maiori...       neg      0  \n",
       "2      Primeiro de tudo eu odeio esses raps imbecis, ...       neg      0  \n",
       "3      Nem mesmo os Beatles puderam escrever músicas ...       neg      0  \n",
       "4      Filmes de fotos de latão não é uma palavra apr...       neg      0  \n",
       "...                                                  ...       ...    ...  \n",
       "49454  Como a média de votos era muito baixa, e o fat...       pos      1  \n",
       "49455  O enredo teve algumas reviravoltas infelizes e...       pos      1  \n",
       "49456  Estou espantado com a forma como este filme e ...       pos      1  \n",
       "49457  A Christmas Together realmente veio antes do m...       pos      1  \n",
       "49458  O drama romântico da classe trabalhadora do di...       pos      1  \n",
       "\n",
       "[49459 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkJh1Lhov_dV"
   },
   "source": [
    "## Abordagem Feature-based\n",
    "\n",
    "* Usa o modelo de linguagem para gerar os embeddings, o qual serve de entrada para o classificador.\n",
    "\n",
    "* O classificador é treinado para gerar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10809,
     "status": "ok",
     "timestamp": 1680116617630,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "h-16UsPwvPn5",
    "outputId": "d0af9a4b-154f-43d1-8814-a4b0bf3c17e8"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "cba2a1f38a3345078c88e036d2936ac3",
      "e5d3c57dc16d49d39acbf892df9752c6",
      "5d8a5bf90cc64ff8a50b298b02e8b57a",
      "006f5366d50640bf8b6ed1c7cbe6b780",
      "06302fed845c48b98d26d1223173e29d",
      "17c6874004e2421a843fb0b9133bf54e",
      "990de0407fef43b380a1be1e17755d67",
      "2d5357cea5994bed90eb413bc5c8f15a",
      "ef80ae8e193e46aa98cebdd992897c90",
      "f761891f7c6e40208781c4730ee381cc",
      "a3ed45f08d81441483b62385e4756318",
      "16579a8254ec4e34a8df51a07d2f5cf3",
      "cfd8282f6c7543b7a5bbe23fcf483db1",
      "d24f39c93ea34f1687ef0de19d77146c",
      "3ef4323c8ae24b20bfaa485426b06df3",
      "dc473f1a937b4aceb82ba3bfb9651995",
      "4dec09a9cd2e4b3e97fca94142ac2447",
      "9d2d3e69369d43408a70e58c47efc0fb",
      "8df5a7b2f95a44888b142a75ec3fc8c6",
      "6ffa4859021b47daa19163c589b8bad5",
      "622333dbcdf94eb4922e7f60d7af98b3",
      "4236c539ad6e474db83275183753602d",
      "07276c1f47a94daab5ef3ff5ca0625d4",
      "8a68cd2ce3334688b15e3c9a0b45ccc2",
      "2eb30c0fee6d4159ba7dcc95c2996119",
      "3ebc052066dd4dfdae4c6b76c317a9a0",
      "048585850a84404d9d046ab00e33f28f",
      "bc0991f1e3a34482894d3e272a428b0f",
      "353d5f4692ce4224a1dd989d48b565fe",
      "4cc5a3663f5c48619fe44bbb774903f9",
      "cc15c9075f374d2b899056e2f968c387",
      "2450423e1251433789bd9ed0c5dbfc0c",
      "4ec4090ee0674fac92ec2b8b402e45ca",
      "2039946865b34c27a1393eff4b8c9879",
      "3df675b2b4724fc6996cb386dea4fe9a",
      "c1e523b52bda4869b86b6b483a328884",
      "8e3e81db27a84c7daced38043a4c7c9b",
      "4b18c597207149dab44cfab95acf6b12",
      "1684697a23ac4fa4a5e36e72ad3b1dbb",
      "412826b76a7b46e4a65faaa19ffe10cb",
      "50c69d7d18eb418fbf6623e55f2a81a8",
      "a86d753a0aa04115b3c71e87337a4af1",
      "9cebe9f719244064b4247b4b4a17cd7a",
      "908b2a8094d940f3b69f638423f46926",
      "ef8fa493c1604ca3b580c4386cf91bfc",
      "54ca153acdf343e683dc269d0ed88467",
      "16b9dd32aedb4037ba8aa968442dcc7c",
      "10913bb63ee24e429c40e6812d7951d1",
      "0d26d6d3d5974d4186f8d349c9106c45",
      "54c508e30b4241d3af3d714b36beed1a",
      "28a59df9f94d478dbefc02339404599a",
      "6055117171de413fb7febd123d2a9688",
      "1ce2c1ac79d1407a8f024459d7530129",
      "7f66e81e0ad54b638508129049c2a6ae",
      "ee33990fe0b246da839d06f3a234e7ea",
      "65e89a54b30d46c4b85701bcdc2cd7a3",
      "6c9e8b1a6ffa4a488d8b8338bb23483a",
      "5e7f1b3164a14f0f993836a3483f83fc",
      "9b28a10088ef461c99240b3e00d0cbed",
      "8d818c9d71a44cb0bd0db00db228b9ef",
      "34dd1390936446509a4f9f44022315a6",
      "34c95de6207f481497f961b8e25dad66",
      "4452e2da0e0d454ab29feb6b46a261b4",
      "c5e6dc4e37de4d86a513786bd1fe10f0",
      "bc20a9b065274880b157c1b67342f665",
      "15b6808d3766433b81320b576ec132e9"
     ]
    },
    "executionInfo": {
     "elapsed": 15339,
     "status": "ok",
     "timestamp": 1680116918273,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "WWtctDrJwOR5",
    "outputId": "11ab2e0a-3a7e-4bd7-cae0-27120f114d72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tulio\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████████████████████████████████████| 210k/210k [00:00<00:00, 14.0MB/s]\n",
      "C:\\Users\\Tulio\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Tulio\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)in/added_tokens.json: 100%|██████████████████████████████████████████████████| 2.00/2.00 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████| 112/112 [00:00<?, ?B/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████| 43.0/43.0 [00:00<00:00, 43.0kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████| 647/647 [00:00<00:00, 633kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████| 438M/438M [09:31<00:00, 767kB/s]\n",
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer_bertimbau = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "model_bertimbau = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1680117011513,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "Z_0C84S5xWid",
    "outputId": "377a5534-0dd7-4ff9-d209-7a7e1648f274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bertimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y5sKq5QNxxCw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# conversão para tokens e identificação através do id\n",
    "input_ids = torch.tensor(tokenizer_bertimbau.encode('Estudando modelos de linguagem contextualizados', add_special_tokens=True, max_length=512, truncation=True)).unsqueeze(0)\n",
    "\n",
    "output = model_bertimbau(input_ids, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1680117864057,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "_fH7J6fWz7-x",
    "outputId": "22cc2d56-38c6-41d7-abf1-ef2b6450d043"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 13025,   214,  4585,   125,  4616, 18880,  2066,  3833,   102]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1680117866035,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "AIbD25Kn0Br7",
    "outputId": "eea8c594-f52b-4d42-8b90-6e7aeaa2c378"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Estuda',\n",
       " '##ndo',\n",
       " 'modelos',\n",
       " 'de',\n",
       " 'linguagem',\n",
       " 'contex',\n",
       " '##tual',\n",
       " '##izados',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# não tokeniza por palavra mas sim pelo vocabulario (algoritmo wordpiece)\n",
    "\n",
    "tokens = tokenizer_bertimbau.convert_ids_to_tokens(input_ids[0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680118224605,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "poLpmvXv0X-A",
    "outputId": "ce937cc4-5796-4db5-c24f-bbf5d986e44b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0][0])\n",
    "# 10 embeddings para 10 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1680118234997,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "ouhXMQ2j1ZkG",
    "outputId": "b841c054-693e-4fb0-ec58-ab27c62af9ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0][0][0])\n",
    "# 768 posiçoes para cada embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1680118330321,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "puvoRvLY2bhK",
    "outputId": "e3f365d8-7400-4cfd-ea5e-dea3ded901d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4259e-01,  4.0103e-01,  9.1296e-01,  2.8389e-01, -7.8744e-02,\n",
       "         5.7209e-01,  6.0349e-01,  9.3607e-02,  1.6760e-01,  5.3643e-01,\n",
       "        -1.6446e-01, -6.3722e-02, -4.0051e-01,  8.6854e-01,  8.3990e-02,\n",
       "        -6.1482e-01,  2.9263e-01,  3.1990e-01, -1.9013e-01,  6.1508e-01,\n",
       "         1.9000e-01, -3.3548e-01,  2.6052e-01, -4.5865e-01,  3.4804e-01,\n",
       "         4.4601e-01, -3.1722e-01,  4.3954e-01,  1.2926e-01, -1.8389e-01,\n",
       "        -1.8486e-01,  2.8515e-02, -4.8374e-01, -1.4387e-01,  1.2798e-01,\n",
       "        -3.2165e-01,  5.3915e-01,  1.0934e-01,  2.6519e-01,  1.7941e-02,\n",
       "        -2.1396e-01, -2.6194e-01, -4.8170e-01, -1.6534e-01, -5.4345e-01,\n",
       "        -3.9526e-01, -7.3860e-02, -2.0253e-01, -4.4021e-01,  6.8335e-02,\n",
       "         2.8324e-01, -1.1216e-01,  4.9492e-01,  4.8311e-01,  4.5922e-01,\n",
       "        -5.0580e-02,  1.7564e-01, -3.7993e-01,  1.2108e-01,  5.1453e-01,\n",
       "         3.5038e-01, -3.3191e-01,  9.0486e-03, -2.1669e-01, -2.5346e-02,\n",
       "         2.2016e-01,  8.9177e-02, -1.1540e-01, -5.5670e-01,  5.3280e-01,\n",
       "        -5.9782e-03, -9.3671e-02,  9.1718e-02, -5.8370e-02, -4.9812e-01,\n",
       "         1.3570e-01,  4.7701e-01,  5.8283e-01, -8.2688e-01, -1.8849e-01,\n",
       "         5.2327e-01,  3.1058e-01, -4.7626e-01,  2.5771e-01, -1.7606e-01,\n",
       "         6.6624e-01,  2.6322e-01,  3.4616e-01, -1.4824e-02, -5.2374e-01,\n",
       "        -2.9726e-02,  1.4052e-01, -6.3165e-03,  1.2063e-01,  4.6486e-01,\n",
       "        -4.0813e-02, -5.2245e-01, -8.0079e-01, -2.3280e-01,  2.0463e-02,\n",
       "         6.8186e-01, -1.4488e-01,  9.5227e-01,  9.9023e-02,  4.4286e-02,\n",
       "         6.7277e-02, -1.2587e-01, -3.0998e-01,  2.7248e-01,  5.0443e-01,\n",
       "        -2.0351e-01,  1.1059e-01,  1.7017e-01,  8.8277e-01,  5.1205e-01,\n",
       "         5.9085e-02,  8.8038e-02, -1.9086e-01,  4.0393e-01, -3.7499e-01,\n",
       "        -2.5699e-01, -5.6044e-02, -6.1811e-01,  5.1670e-02,  3.1350e-01,\n",
       "        -7.6242e-01, -3.3297e-01, -3.5796e-01,  5.6782e-01,  3.8125e-01,\n",
       "         7.1272e-02, -9.5732e-02, -4.2789e-01,  3.4439e-01,  5.8220e-01,\n",
       "        -3.5422e-01,  4.7916e-02,  3.9431e-01,  3.4361e-01,  1.4593e-03,\n",
       "         6.8206e-01,  3.4467e-02, -2.6688e-01,  3.9960e-01,  3.5858e-01,\n",
       "        -4.2109e-02, -1.3278e-01, -4.8665e-02, -1.2543e-01,  3.2110e-01,\n",
       "        -7.9777e-02,  6.6876e-02, -2.7372e-02, -5.9884e-02, -3.0639e-01,\n",
       "         1.1135e-01,  4.6682e-02, -2.6479e-01,  3.4969e-02,  1.9421e-01,\n",
       "         6.1220e-01, -7.6725e-01, -4.2096e-01,  8.6355e-02, -1.9949e-01,\n",
       "        -4.1771e-01, -8.7003e-02,  2.0694e-01, -8.6694e-02,  4.2754e-01,\n",
       "        -3.9354e-01,  2.6558e-01, -5.9265e-02,  4.0861e-01,  5.5524e-01,\n",
       "        -7.8803e-01, -2.3629e-02, -2.1680e-01, -3.9308e-01,  1.4361e-01,\n",
       "        -3.4297e-01,  2.2140e-01, -1.7244e-01,  1.2869e-01,  1.8043e-01,\n",
       "         3.0727e-01,  2.7531e-02,  1.2453e-01,  5.2651e-03,  1.6985e-02,\n",
       "         2.6535e-01,  3.4222e-01, -1.6604e-01, -2.4545e-01, -1.2996e-01,\n",
       "         9.1113e-03,  5.0558e-01,  1.8362e-01, -5.1679e-02,  3.8834e-02,\n",
       "        -4.0787e-01, -6.1170e-03, -2.6826e-01, -9.7332e-02,  6.8049e-01,\n",
       "         9.3891e-01,  2.8667e-01, -9.8612e-01, -4.7364e-01,  1.1553e+00,\n",
       "         2.6407e-02,  3.1963e-01, -3.6762e-01,  4.6506e-02, -2.2748e-01,\n",
       "         3.2103e-01,  1.2406e-01,  7.1326e-02,  4.4908e-01, -1.2208e-01,\n",
       "         4.1352e-01, -3.6485e-01, -4.6271e-01,  7.5673e-02, -1.2834e-02,\n",
       "         3.7877e-01,  4.4472e-01,  6.2748e-02, -3.7712e-01,  1.9632e-01,\n",
       "        -5.5664e-01, -5.0969e-01, -2.7582e-01, -4.8720e-02, -3.9713e+00,\n",
       "         2.2728e-01,  3.1940e-02, -2.0909e-01,  1.7665e-01, -4.1244e-01,\n",
       "         9.2020e-02, -3.1284e-01,  5.1526e-01, -9.9439e-02,  4.7733e-01,\n",
       "        -3.0933e-01, -2.1892e-01,  1.1611e+00,  2.0652e-01, -2.9817e-01,\n",
       "        -5.4141e-01, -2.5594e-01, -1.6283e-01,  1.6952e-02, -1.6839e-01,\n",
       "        -1.1075e-01, -1.6211e-02, -9.2057e-02,  6.9121e-01, -5.2920e-01,\n",
       "        -5.5708e-01,  2.1713e-01, -1.3852e-01,  2.5455e-01, -4.2138e-01,\n",
       "         3.3337e-01, -1.0787e-01,  3.5286e-01,  1.9759e-01,  1.3203e-01,\n",
       "        -2.5686e-01, -3.3743e-01,  3.0095e-02, -5.1947e-01,  6.0875e-01,\n",
       "        -1.7284e-01,  2.5742e-01,  7.1327e-01, -6.5718e-01,  1.0303e-01,\n",
       "         6.0286e-01, -2.1404e-01, -6.5568e-02,  7.4232e-01, -2.6614e-01,\n",
       "         5.8183e-01, -4.2875e-01, -3.7039e-01, -1.5986e-01,  1.9996e-01,\n",
       "        -6.2107e-02, -1.3661e-01,  6.9042e-02,  1.1696e-01, -2.8454e-02,\n",
       "         2.4288e-02, -1.8884e-01, -4.0752e-02,  1.3834e-01,  4.9290e-01,\n",
       "         2.4852e-01,  3.5829e-01,  3.4939e-01,  9.3421e-02, -2.2794e-01,\n",
       "        -1.0043e-01, -5.6569e-01,  1.3817e-01, -5.8886e-02, -2.0887e-01,\n",
       "        -5.7193e-02, -6.4952e-02, -3.1864e-01,  2.2519e-01,  2.1451e-02,\n",
       "        -1.5182e-01, -2.3952e-01, -2.7554e-01, -4.4842e-01,  1.0155e+00,\n",
       "        -4.4712e-02, -6.2855e-01,  3.4642e-03,  3.8780e-01, -3.8845e-01,\n",
       "         4.7406e-01, -2.5167e-01,  3.6867e-01,  1.3583e-01,  3.8842e-02,\n",
       "        -3.2579e-01,  7.7595e-01, -5.1194e-02, -4.9880e-02,  1.4154e-01,\n",
       "        -3.8172e-02, -1.9083e-02, -5.5083e-01, -6.1534e-01, -6.0154e-02,\n",
       "         5.1425e-01, -1.2545e-01,  1.8108e-03,  7.8958e-03,  1.2549e-01,\n",
       "        -8.5056e-01,  1.1001e-01,  2.9986e-01,  3.2170e-02, -2.2980e-01,\n",
       "         1.3244e-01,  8.4599e-02,  2.8388e-01, -4.8314e-01, -3.5182e-01,\n",
       "         1.8456e-01, -2.0282e-01, -1.2850e-01, -4.1471e-02,  7.3175e-01,\n",
       "        -7.9972e-02,  2.2738e-01,  5.4230e-02, -5.1488e-01, -2.2840e-01,\n",
       "        -2.4705e-01, -5.8670e-01,  1.3107e-01,  3.2433e-01,  3.8858e-01,\n",
       "        -6.4036e-02,  7.1901e-01, -2.9212e-01, -3.8576e-01,  8.1391e-01,\n",
       "        -1.5356e-01,  5.7299e-02, -4.5430e-01, -4.7085e-01,  8.7180e-01,\n",
       "        -3.1076e-01, -1.5046e-01,  1.9603e-01, -4.5385e-02,  3.0897e-01,\n",
       "        -4.2639e-01, -1.0761e-01,  2.5459e-02, -9.0403e-02,  2.9322e-01,\n",
       "         3.0021e-01,  2.3706e-01, -6.7725e-01,  3.5881e-01, -4.3502e-01,\n",
       "        -4.2248e-01, -3.9752e-01,  7.3167e-02,  3.0043e-01, -3.9558e-01,\n",
       "         2.6287e-01,  2.5220e-01,  4.1586e-03,  4.7834e-01, -1.8854e-01,\n",
       "         2.3167e-01,  7.3529e-01,  2.0692e-01, -1.5291e-01,  1.4104e-01,\n",
       "         1.5887e-01,  3.5182e-02, -5.5109e-01,  2.5585e-01, -2.1191e-01,\n",
       "        -1.2629e-01, -2.8073e-01, -1.6491e-01, -4.2582e-01,  3.1866e-01,\n",
       "         2.6570e-01,  4.5643e-01,  1.2022e-01, -4.9507e-01, -1.6088e-01,\n",
       "        -1.7280e-01,  9.8317e-02, -1.2660e-01, -6.9366e-01,  2.0868e-01,\n",
       "        -1.2424e-01,  3.3413e-01, -3.1395e-03,  8.7406e-02,  3.2974e-01,\n",
       "        -2.5204e-01, -4.7801e-01, -3.3385e-01, -3.3969e-01,  4.5601e-01,\n",
       "        -7.5504e-02, -2.6661e-01,  1.6934e-01,  1.2663e-01, -2.9792e-01,\n",
       "         3.7438e-01, -1.1341e-01, -1.9180e-01,  3.3816e-01, -2.0648e-01,\n",
       "        -1.4788e-01, -8.4129e-01,  2.9805e-01, -1.5839e-01, -4.9309e-01,\n",
       "        -6.8883e-01, -9.9230e-03,  5.5363e-02,  4.3322e-01, -7.1854e-01,\n",
       "         2.9056e-01,  3.0446e-01,  9.9647e-02, -1.6634e-01, -5.3057e-01,\n",
       "         1.7907e-01, -5.3126e-01,  5.9582e-01,  6.8635e-02,  8.0814e-02,\n",
       "        -4.2197e-01, -8.0068e-03, -2.9720e-01, -4.9904e-02, -5.6412e-01,\n",
       "         2.2632e-01, -2.7863e-02,  4.0076e-01, -1.7582e-01,  5.5865e-01,\n",
       "         2.0942e-01,  5.7823e-01,  3.2632e-01, -5.4193e-01,  3.4909e-01,\n",
       "        -5.0249e-02,  7.6685e-01, -2.8094e-01, -5.5404e-01, -5.0769e-01,\n",
       "        -3.3293e-01,  4.1478e-01,  2.7715e-01, -3.3230e-01, -1.0455e-01,\n",
       "        -1.3904e-01,  9.5323e-01, -4.1183e-01, -3.7694e-01,  4.1642e-02,\n",
       "         3.1495e-02, -3.4660e-01, -2.7221e-02,  6.1265e-02, -4.6569e-01,\n",
       "        -8.1500e-02, -1.7217e-01, -1.1173e-02, -2.0296e-01, -4.7486e-01,\n",
       "         7.6285e-02, -1.1140e+00,  3.5520e-01, -1.1534e-01, -4.6863e-01,\n",
       "        -5.5119e-01, -2.1917e-01,  3.7198e-01, -1.9105e-01,  1.9471e-01,\n",
       "        -1.6884e-01,  2.3704e-01,  1.2205e-01, -1.9958e-01,  2.9691e-01,\n",
       "        -1.7684e-01, -4.5205e-01,  3.1087e-02, -5.4096e-02,  5.5753e-01,\n",
       "        -5.2865e-02, -1.0240e-01,  1.3920e-01,  1.2341e-01,  1.1104e-01,\n",
       "         7.8396e-01,  1.5856e-01, -5.0676e-01,  2.6085e-02,  5.4555e-01,\n",
       "         3.0277e-03, -3.4135e-02,  1.9932e-02,  1.0647e-02, -2.5810e-01,\n",
       "        -7.8150e-02, -7.3008e-02,  8.9598e-02,  5.8390e-02, -2.3692e-01,\n",
       "        -1.0014e-01,  1.6541e-01, -1.3212e-01,  7.3130e-02,  3.8873e-01,\n",
       "         3.1082e-01,  1.6166e-01, -1.7683e-02,  3.2625e-02, -1.5888e-01,\n",
       "         3.0572e-01, -2.1440e-01,  1.5891e-01, -1.8136e-01, -5.8755e-01,\n",
       "        -1.0196e-01,  1.5402e-01,  9.2408e-02,  1.5376e-01, -1.7642e-01,\n",
       "        -1.4484e-01, -3.6517e-01, -1.7015e-01, -4.4517e-01, -3.4160e-01,\n",
       "         1.5432e-01, -3.6633e-01,  2.7280e-01,  4.4877e-01, -4.1527e-01,\n",
       "         6.0853e-01,  3.3787e-01,  4.6552e-01, -1.4196e-01, -5.4940e-01,\n",
       "         1.7114e-01,  2.8587e-01,  5.0824e-01,  2.0162e-01,  2.4016e-01,\n",
       "        -3.1904e-01, -1.0463e-01,  2.4511e-01, -4.7340e-02,  4.2133e-01,\n",
       "         4.3387e-01,  1.2177e-01, -1.4673e-01,  1.8774e-01, -3.4389e-01,\n",
       "        -2.9995e-01, -3.4672e-01, -2.0469e-02, -7.5778e-04, -2.2161e-01,\n",
       "        -3.1985e-02, -5.0820e-01,  2.6590e-01, -2.0170e-01, -5.1045e-01,\n",
       "         1.0562e-01,  6.2501e-02, -1.1314e-02,  5.8324e-01, -4.0253e-01,\n",
       "        -1.7542e-01,  1.8375e-02, -4.7358e-01,  4.8514e-01, -2.7978e-01,\n",
       "         4.2184e-01,  3.4382e-01, -3.9666e-01,  1.7222e-01,  1.6629e-02,\n",
       "        -3.6852e-01,  8.8474e-01, -4.0228e-01, -1.3374e-01, -8.7968e-01,\n",
       "         7.3266e-01,  1.3814e-01,  5.6960e-01,  6.3580e-02,  3.5599e-01,\n",
       "        -2.1772e-02, -3.2059e-01, -5.5243e-01, -3.7675e-01, -8.6593e-02,\n",
       "        -1.7623e-01,  2.5289e-02,  1.9902e-01,  2.7425e-01, -3.1451e-01,\n",
       "         3.5237e-01,  6.0594e-02,  3.2075e-01, -2.9705e-01,  3.2770e-01,\n",
       "        -8.8121e-02, -1.7430e-01,  5.6003e-01,  1.4023e-01, -1.1202e-01,\n",
       "        -5.2971e-03, -3.5451e-01, -5.0805e-01,  2.5049e-01,  5.5035e-01,\n",
       "         7.8229e-01,  4.1270e-01,  5.0207e-01, -1.4099e-01,  1.0885e-01,\n",
       "         8.3289e-01, -2.2609e-01,  2.5077e-01, -9.0478e-02,  6.0542e-01,\n",
       "        -2.7218e-01, -2.4202e-01,  4.6360e-01, -4.7917e-01, -3.3314e-01,\n",
       "        -3.3028e-02,  9.6409e-02, -4.6793e-01,  6.0713e-01, -3.3818e-01,\n",
       "        -1.5741e-01,  5.2580e-02,  3.6228e-01, -5.5028e-01,  7.0020e-01,\n",
       "         1.7101e-01,  2.3467e-02, -1.8092e-02, -7.1659e-02, -7.9759e-02,\n",
       "        -6.5872e-02,  2.9150e-01,  2.1639e-02, -2.6776e-01,  1.5244e-01,\n",
       "         3.9091e-01,  3.7727e-01,  3.3987e-01,  4.1154e-01,  9.8158e-02,\n",
       "        -5.9210e-01, -6.6009e-01,  4.4599e-01, -7.5404e-01, -1.3151e-01,\n",
       "        -3.0787e-01, -9.7713e-02, -1.1483e-01,  3.4401e-01, -1.8441e-01,\n",
       "         6.4080e-02,  5.5534e-01,  8.5189e-02, -1.6907e-01, -1.4844e-02,\n",
       "         1.0961e-01,  4.4168e-02, -3.1624e-01, -6.6104e-02,  2.1613e-01,\n",
       "         1.1351e-01,  9.4474e-02, -7.4844e-01,  1.1117e-01,  1.1575e-01,\n",
       "         3.0395e-01,  2.0378e-01,  1.4713e-02, -5.2858e-01,  8.9237e-02,\n",
       "        -1.8677e-01, -2.9733e+00,  2.4156e-01,  5.3938e-01,  2.5119e-01,\n",
       "         3.2299e-01, -1.5091e-01,  6.3701e-01,  5.1108e-01,  1.2335e-01,\n",
       "         1.7433e-01, -8.6044e-02, -7.4321e-02, -2.2285e-02,  7.9525e-01,\n",
       "        -2.6109e-01,  4.1003e-01,  1.2145e-01, -1.0869e-01, -3.8137e-01,\n",
       "        -4.4278e-01, -3.9568e-01,  4.0937e-01, -4.5596e-01,  5.9077e-01,\n",
       "         2.2718e-01, -2.3224e-01, -4.4807e-01,  7.5031e-01, -4.5787e-01,\n",
       "         1.0065e-01, -3.7825e-01, -4.6642e-02,  4.8667e-01,  2.7483e-01,\n",
       "        -5.1707e-02, -1.4012e-01, -9.0459e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding de 1 token\n",
    "output[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRMy6cI227By"
   },
   "source": [
    "## Embeddings a partir do Sentence Transformers\n",
    "\n",
    "Faz o embedding de toda a setença e não somente dos tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10302,
     "status": "ok",
     "timestamp": 1680118449313,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "5CyeYvM72y9P",
    "outputId": "8c8f12d8-94b2-4c88-c089-da9132773cbf"
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10145,
     "status": "ok",
     "timestamp": 1680118623855,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "53fYGiOk3NjX",
    "outputId": "6101518a-7f48-42bd-fe90-ddbd314e41ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)f0baa/.gitattributes: 100%|█████████████████████████████████████████████| 391/391 [00:00<00:00, 387kB/s]\n",
      "Downloading (…)e10def0baa/README.md: 100%|████████████████████████████████████████| 3.60k/3.60k [00:00<00:00, 3.58MB/s]\n",
      "Downloading (…)aa/added_tokens.json: 100%|██████████████████████████████████████████| 2.00/2.00 [00:00<00:00, 1.95kB/s]\n",
      "Downloading (…)0def0baa/config.json: 100%|█████████████████████████████████████████████| 647/647 [00:00<00:00, 648kB/s]\n",
      "Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████| 438M/438M [01:26<00:00, 5.06MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████| 112/112 [00:00<?, ?B/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████| 43.0/43.0 [00:00<00:00, 43.0kB/s]\n",
      "Downloading (…)e10def0baa/vocab.txt: 100%|██████████████████████████████████████████| 210k/210k [00:00<00:00, 6.98MB/s]\n",
      "No sentence-transformers model found with name C:\\Users\\Tulio/.cache\\torch\\sentence_transformers\\neuralmind_bert-base-portuguese-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\Tulio/.cache\\torch\\sentence_transformers\\neuralmind_bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "model.max_seq_length = 512\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680118644546,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "or5WESFY3vEE",
    "outputId": "29b56212-2ad4-4b40-e2ea-c1ea30928a93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 13025,   214,  4585,   125,  4616, 18880,  2066,  3833,   102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenize(['Estudando modelos de linguagem contextualizados'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3625,
     "status": "ok",
     "timestamp": 1680118723277,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "ygNXHC3T3_rk",
    "outputId": "bf31e1cb-66e4-4ae0-c948-b758523a27c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.08376477e-03,  5.16501293e-02,  8.27929854e-01,  1.08459711e-01,\n",
       "        1.51964694e-01,  2.96854526e-01, -1.50732393e-03, -1.26951247e-01,\n",
       "       -4.76407148e-02,  5.82769793e-03,  2.24021241e-01,  5.75402454e-02,\n",
       "       -2.36572579e-01,  2.78626978e-01, -3.14570107e-02, -4.04580206e-01,\n",
       "        1.26978070e-01, -1.18314192e-01,  3.60915735e-02,  3.31545830e-01,\n",
       "       -1.12002730e-01, -9.04822722e-02, -1.58047900e-01, -4.21076477e-01,\n",
       "        2.17379570e-01,  3.76325846e-01, -3.26602086e-02,  1.42404899e-01,\n",
       "       -1.34578526e-01, -5.89618683e-01,  2.05488563e-01, -3.94075327e-02,\n",
       "       -3.70831072e-01, -7.68706352e-02,  2.41237327e-01, -1.71949580e-01,\n",
       "        6.19709969e-01,  2.19713062e-01,  4.98909146e-01,  1.97408989e-01,\n",
       "       -1.40037388e-01, -1.64626390e-01, -9.99341309e-02, -2.78383255e-01,\n",
       "       -1.79463580e-01, -3.32419932e-01, -1.76172376e-01,  8.85227043e-03,\n",
       "       -2.88362056e-01,  6.84021339e-02,  7.66360834e-02, -1.14154860e-01,\n",
       "        1.86520964e-01,  3.79879892e-01,  4.43549454e-02,  9.37143713e-02,\n",
       "       -7.41611123e-02, -3.82010609e-01,  2.10181484e-03,  9.72496122e-02,\n",
       "        1.55191332e-01, -1.98614150e-01,  1.60129875e-01, -1.07938256e-02,\n",
       "       -1.89205378e-01,  2.41692990e-01,  9.45427269e-02,  3.75882722e-02,\n",
       "       -2.68172950e-01,  4.63296592e-01,  8.39741454e-02,  1.22057632e-01,\n",
       "        8.88686329e-02, -1.85268328e-01, -1.00359157e-01,  1.39021426e-01,\n",
       "        1.16107121e-01,  1.36451736e-01, -4.06153202e-01,  3.70277092e-02,\n",
       "       -1.58498285e-03,  1.34989887e-01, -1.43922031e-01,  2.74428964e-01,\n",
       "       -1.50850505e-01,  3.81041229e-01,  3.65603358e-01,  1.70884013e-01,\n",
       "        3.44625533e-01, -8.12004227e-03,  4.51033860e-02,  3.01653266e-01,\n",
       "        1.61184683e-01,  2.37266108e-01,  3.41322064e-01,  1.93389237e-01,\n",
       "       -2.12486655e-01, -2.92708337e-01, -2.73969293e-01,  7.75070414e-02,\n",
       "        1.49645492e-01, -1.15272067e-01,  2.96146333e-01, -5.67160845e-02,\n",
       "        4.55878556e-01, -2.07455661e-02,  1.67709827e-01,  1.32904528e-02,\n",
       "       -1.40751332e-01,  3.36923480e-01,  3.64895724e-02,  3.43750536e-01,\n",
       "        2.31329829e-01,  3.31185669e-01,  2.30168939e-01, -3.67897332e-01,\n",
       "       -1.45611346e-01, -2.69316018e-01,  5.14579535e-01, -3.40452135e-01,\n",
       "       -8.44781846e-02, -1.98920637e-01, -4.77745473e-01,  2.65336812e-01,\n",
       "        1.00222968e-01, -2.47292712e-01, -2.61296183e-01, -3.27306974e-04,\n",
       "        2.77393818e-01,  1.09667204e-01, -2.98058659e-01,  9.20514986e-02,\n",
       "       -3.33206773e-01, -1.75419644e-01,  4.31700647e-01, -2.15780497e-01,\n",
       "        1.75598070e-01, -4.59862947e-02,  9.61369425e-02, -9.96229500e-02,\n",
       "        2.67638624e-01, -5.16457781e-02,  7.72821018e-03,  7.91400895e-02,\n",
       "       -1.82984263e-01, -2.77237475e-01, -4.01576132e-01,  3.64609569e-01,\n",
       "       -3.34682986e-02, -4.56145890e-02, -2.22535133e-01,  1.88855261e-01,\n",
       "        5.52901402e-02, -1.50246769e-01, -4.50975567e-01,  1.59233302e-01,\n",
       "       -1.09814361e-01, -3.19571584e-01,  8.32560472e-03,  2.54934758e-01,\n",
       "        5.63681014e-02, -2.85759926e-01, -2.99398713e-02, -3.19169134e-01,\n",
       "       -5.76184969e-03, -4.44316775e-01,  1.17956195e-02,  2.77630091e-01,\n",
       "        1.10554278e-01,  1.70745447e-01, -4.98879813e-02,  3.17415707e-02,\n",
       "       -2.44475812e-01,  3.16424102e-01,  4.37742412e-01, -9.98386070e-02,\n",
       "       -8.79938155e-02, -1.13137208e-01, -1.56501055e-01,  8.16611424e-02,\n",
       "       -3.52023304e-01,  1.91439673e-01, -1.91914499e-01, -3.18573751e-02,\n",
       "       -4.64210175e-02,  3.06792796e-01,  1.21317029e-01,  1.13595404e-01,\n",
       "        3.75923812e-02, -3.03622931e-02,  1.11980222e-01,  4.19558547e-02,\n",
       "       -3.01272452e-01, -1.58542037e-01, -3.35673571e-01, -2.05501884e-01,\n",
       "        2.57399976e-01,  1.28744375e-02, -7.03641307e-03,  1.55606329e-01,\n",
       "       -2.83725202e-01, -1.16934076e-01, -3.31123501e-01, -9.23788995e-02,\n",
       "        1.41113192e-01,  2.41033167e-01,  2.75316350e-02, -2.63217509e-01,\n",
       "       -3.87263119e-01,  6.12837493e-01, -6.26834482e-02,  1.69158444e-01,\n",
       "        2.39968255e-01, -1.78269789e-01, -1.34865552e-01,  2.80290306e-01,\n",
       "        2.34920830e-01,  4.71382216e-02,  3.07598591e-01,  8.38482939e-03,\n",
       "        2.32480407e-01, -2.43033975e-01, -4.78450835e-01,  4.60017398e-02,\n",
       "       -7.81496540e-02, -5.60485199e-02,  2.45505378e-01, -1.33135796e-01,\n",
       "       -2.70652920e-01, -7.24300072e-02, -5.93735874e-01, -1.90627500e-01,\n",
       "       -2.04642624e-01,  3.64983648e-01, -8.89310062e-01,  3.29383492e-01,\n",
       "       -5.17332070e-02,  6.08070083e-02,  1.74703170e-02, -1.77076519e-01,\n",
       "        2.66155422e-01, -4.35878426e-01,  6.04942515e-02,  1.91734056e-03,\n",
       "        1.74633011e-01, -2.62970835e-01, -6.89562559e-02,  4.64130878e-01,\n",
       "        6.87837243e-01, -2.63418525e-01, -5.12641490e-01,  1.92959696e-01,\n",
       "       -1.03127673e-01, -2.12278128e-01, -2.75506377e-01, -2.39435479e-01,\n",
       "       -6.99464753e-02, -5.35851829e-02,  2.07995564e-01, -4.66957003e-01,\n",
       "       -1.80184022e-01,  4.23156351e-01, -1.40152797e-02,  1.38181806e-01,\n",
       "        2.50931174e-01,  1.31100327e-01,  1.15757026e-01,  2.09441617e-01,\n",
       "        2.21159006e-03, -7.19123259e-02, -1.78474128e-01, -1.67202875e-01,\n",
       "        5.08792639e-01, -9.99866948e-02,  1.94218606e-01, -9.41684619e-02,\n",
       "        9.41373333e-02,  4.70104218e-01, -1.90200090e-01,  3.83596271e-01,\n",
       "        3.67471695e-01, -2.50333011e-01, -9.07237828e-02,  6.11982644e-01,\n",
       "       -1.63224667e-01,  2.26407140e-01,  4.79423627e-02, -3.97291511e-01,\n",
       "       -3.71061489e-02,  6.23646751e-02, -3.12633216e-01, -4.82510999e-02,\n",
       "        1.80153400e-01,  1.20183721e-01,  1.94525093e-01, -2.58115232e-01,\n",
       "       -4.68392134e-01,  1.82511006e-02, -7.41519332e-02,  4.30119038e-02,\n",
       "        1.21362351e-01,  7.46273935e-01, -1.04427366e-02,  1.54623866e-01,\n",
       "        2.22258478e-01, -1.92611545e-01, -1.21736564e-01,  1.14078566e-01,\n",
       "        2.48806402e-01, -1.85891345e-01, -2.63000280e-01,  2.32283905e-01,\n",
       "       -3.11058640e-01,  3.09197605e-01, -1.08451940e-01,  1.33938119e-01,\n",
       "        4.11535203e-02, -2.11045459e-01, -3.73275697e-01,  5.06855011e-01,\n",
       "       -1.55580312e-01,  1.15323566e-01,  2.39531249e-01,  4.47007507e-01,\n",
       "       -2.55793035e-01,  3.87434304e-01,  2.96450444e-02, -4.30750549e-02,\n",
       "       -3.28032672e-02, -6.81401044e-03, -8.41972381e-02,  5.28887451e-01,\n",
       "       -3.14246386e-01, -2.52856404e-01,  4.17456403e-02, -7.51400441e-02,\n",
       "       -8.89723748e-02, -2.23593429e-01, -8.52087975e-01, -9.21761966e-04,\n",
       "        6.08861446e-05,  7.78411776e-02,  8.26332718e-02,  2.82388210e-01,\n",
       "        4.01610956e-02, -8.99606347e-01, -1.32726043e-01,  1.40105039e-01,\n",
       "        1.06463000e-01, -4.16162238e-02,  1.54907152e-01,  4.90991548e-02,\n",
       "        4.34530407e-01, -3.73675019e-01, -2.69257963e-01,  4.65676218e-01,\n",
       "       -3.95267047e-02, -7.82664865e-02,  1.28222167e-01,  1.73885390e-01,\n",
       "        2.37086490e-01,  2.06625193e-01,  5.09331599e-02, -2.35061124e-01,\n",
       "       -3.15648526e-01,  1.71706870e-01, -1.26854137e-01, -2.25989625e-01,\n",
       "        5.90070710e-02,  3.37889344e-01,  7.81734511e-02,  1.24032713e-01,\n",
       "       -3.12112272e-01, -2.16242075e-01,  3.46767873e-01, -2.31954008e-01,\n",
       "       -2.47824594e-01, -4.59022909e-01, -5.09846509e-01,  2.34420866e-01,\n",
       "       -5.54286018e-02, -2.05834419e-01,  2.55120635e-01,  1.80632308e-01,\n",
       "       -2.44137887e-02, -1.03330180e-01, -6.08754642e-02, -1.57307059e-01,\n",
       "        3.09766177e-02,  2.91146487e-01,  1.71885923e-01,  3.88030440e-01,\n",
       "       -5.60007215e-01,  6.71845227e-02, -2.77265310e-01, -3.53718698e-01,\n",
       "       -1.25171453e-01, -1.64350290e-02,  4.07818854e-02, -4.08275835e-02,\n",
       "       -9.10640731e-02, -8.78393650e-02,  9.90511999e-02,  1.19661883e-01,\n",
       "       -3.57544541e-01,  3.55047733e-01,  6.33230090e-01,  1.83962677e-02,\n",
       "        7.96655342e-02,  2.16851518e-01,  2.92735636e-01,  4.79575098e-02,\n",
       "        1.34121059e-02, -4.81629893e-02,  3.40242982e-02,  1.54823363e-01,\n",
       "       -3.20603222e-01, -6.77153915e-02, -2.96462446e-01,  2.58780152e-01,\n",
       "        1.46034926e-01,  6.77188560e-02,  2.78196931e-02, -5.46011746e-01,\n",
       "        3.25084507e-01, -7.99946561e-02,  1.82519868e-01,  2.58724004e-01,\n",
       "       -2.25897163e-01,  1.41791049e-02, -3.28490958e-02,  1.06660604e-01,\n",
       "        1.61009212e-03,  2.66037315e-01,  3.45167145e-02,  1.35379210e-01,\n",
       "       -1.15855411e-01, -6.06196113e-02, -3.82944345e-01,  8.08713660e-02,\n",
       "        3.96735609e-01, -3.97388130e-01, -1.20801898e-02, -2.21341476e-02,\n",
       "       -2.99111843e-01,  6.54991791e-02,  6.25317544e-02,  2.17434950e-02,\n",
       "        1.26187921e-01, -4.18584496e-01, -6.71959966e-02, -3.50868374e-01,\n",
       "        1.18190125e-01,  5.27049676e-02, -3.61824751e-01, -3.84580284e-01,\n",
       "        2.28758454e-01, -1.05644427e-01,  2.12853283e-01, -7.92983949e-01,\n",
       "        6.47054538e-02,  2.85811961e-01, -3.20057049e-02, -1.43321678e-01,\n",
       "       -3.25517058e-01,  1.52906254e-01, -1.19984962e-01,  5.20111918e-01,\n",
       "        1.09583080e-01,  1.70461938e-01, -3.38133186e-01, -1.73231080e-01,\n",
       "       -2.34131411e-01,  1.08576439e-01, -2.44878441e-01,  3.69894207e-01,\n",
       "        4.77401018e-02, -4.57643978e-02, -9.79585126e-02,  3.23397487e-01,\n",
       "        1.38444605e-03,  4.20072168e-01,  7.06777051e-02, -4.59283650e-01,\n",
       "        1.39028087e-01,  1.33434549e-01,  2.26840645e-01, -1.21876024e-01,\n",
       "       -3.58471692e-01, -2.76697546e-01,  1.09433085e-02, -1.18115917e-01,\n",
       "        3.54287207e-01, -4.56650436e-01, -1.04441389e-01,  1.51729494e-01,\n",
       "        4.90763098e-01, -1.22742057e-02,  4.82466698e-01,  5.68813622e-01,\n",
       "        8.06037933e-02,  1.50318965e-01, -1.72444195e-01,  1.69468865e-01,\n",
       "       -2.27785975e-01, -3.69949490e-01, -2.40250036e-01,  9.28932875e-02,\n",
       "       -1.52150020e-01, -1.24133024e-02, -4.98967357e-02, -5.79558074e-01,\n",
       "        1.54044151e-01,  1.14976943e-01, -2.63563544e-01, -3.55486751e-01,\n",
       "       -1.18349968e-02,  3.20982873e-01, -1.01663470e-01,  5.25688902e-02,\n",
       "       -6.20986149e-02,  1.63471311e-01,  3.84943604e-01, -1.27779856e-01,\n",
       "        1.37602299e-01, -3.89239103e-01, -1.44835860e-01, -3.58875930e-01,\n",
       "       -1.20199755e-01,  2.61457115e-01, -1.51009232e-01, -1.83606446e-02,\n",
       "        4.79395464e-02, -9.77577418e-02,  1.52349472e-01,  3.73211712e-01,\n",
       "        2.86737736e-02, -1.30557805e-01, -3.72296721e-02,  3.91796023e-01,\n",
       "        6.31701574e-02, -1.32453829e-01, -2.32852533e-01,  9.17602628e-02,\n",
       "       -1.26250282e-01, -2.59203285e-01, -1.72872990e-01,  3.04292291e-01,\n",
       "        2.44791389e-01, -1.13358818e-01, -1.01903258e-02, -3.29228848e-01,\n",
       "       -6.67842105e-02,  9.23335925e-02,  2.73116291e-01,  8.98037776e-02,\n",
       "        2.10562900e-01, -1.55748174e-01, -3.55932117e-02, -3.44162643e-01,\n",
       "        6.50345534e-02, -2.76765466e-01, -6.44670147e-03, -3.83798033e-02,\n",
       "       -1.22815445e-01, -2.12914631e-01, -6.11651056e-02,  7.51968771e-02,\n",
       "       -1.21497713e-01, -1.31605072e-02, -3.11357267e-02, -6.59201145e-02,\n",
       "       -4.02202368e-01, -1.81092545e-01, -5.94184771e-02,  2.62125373e-01,\n",
       "       -5.17519355e-01, -9.79963094e-02,  1.38652414e-01, -1.22413322e-01,\n",
       "       -2.40990520e-02,  1.20731734e-01,  1.45343155e-01, -2.39096925e-01,\n",
       "       -1.73459709e-01,  1.14541531e-01,  2.12692529e-01,  6.15711391e-01,\n",
       "        2.02884153e-01,  4.23189029e-02, -6.42496571e-02,  1.04808854e-02,\n",
       "        1.46178052e-01,  1.25580896e-02,  3.76338363e-01,  3.10014248e-01,\n",
       "       -1.27325311e-01, -1.64328292e-01,  3.30644362e-02, -6.91223025e-01,\n",
       "       -3.98989856e-01, -4.46172953e-01, -2.58400440e-01, -2.19108298e-01,\n",
       "       -3.67191583e-01, -1.80732198e-02, -4.26270999e-02, -2.26232052e-01,\n",
       "       -3.05290759e-01, -6.58451170e-02,  1.08588804e-02, -1.03888437e-01,\n",
       "       -1.79278344e-01, -1.47105698e-02, -1.48052303e-02,  1.78523302e-01,\n",
       "        1.19974911e-01, -3.48586023e-01,  1.34702787e-01, -1.54327720e-01,\n",
       "        4.51015711e-01,  8.32218304e-02,  1.46206645e-02,  6.39285073e-02,\n",
       "        1.37005240e-01,  7.47546181e-02,  3.77594739e-01, -9.02057588e-02,\n",
       "        7.97713082e-03, -1.25646770e-01,  2.03482628e-01,  1.65224329e-01,\n",
       "        6.54799521e-01, -2.25395754e-01,  2.40246207e-01,  4.80123699e-01,\n",
       "        1.05129674e-01, -9.28203836e-02, -4.29960668e-01, -3.53595018e-02,\n",
       "       -2.85909384e-01,  2.60105044e-01,  6.54187649e-02,  1.50521949e-01,\n",
       "        1.11016966e-01,  1.56301945e-01,  2.34665181e-02,  2.21157163e-01,\n",
       "       -3.35439086e-01,  2.86271989e-01,  2.33103722e-01, -1.34682462e-01,\n",
       "        7.01259226e-02, -5.08108325e-02, -1.61879227e-01, -2.26014763e-01,\n",
       "        3.29461098e-01, -2.09223196e-01, -1.99381262e-01,  5.26039958e-01,\n",
       "        2.34381348e-01,  1.86714277e-01,  5.06113946e-01, -3.23650748e-01,\n",
       "       -1.44659534e-01,  8.09579194e-01, -2.61109114e-01, -1.88581552e-02,\n",
       "        1.93421450e-02,  2.23533943e-01, -1.94074303e-01, -2.16292262e-01,\n",
       "        4.27824080e-01, -3.98517311e-01,  6.73862323e-02,  2.46225804e-01,\n",
       "        8.96222815e-02, -1.26383647e-01, -1.29807949e-01, -1.50354400e-01,\n",
       "       -3.19554478e-01, -3.16840522e-02,  2.19217107e-01, -1.17511943e-01,\n",
       "        4.51767445e-01, -6.00119643e-02,  1.13349319e-01,  1.18837558e-01,\n",
       "        2.12356485e-02, -1.67372495e-01, -1.26113594e-01, -3.12150177e-02,\n",
       "       -5.46367228e-01, -1.48342997e-01, -1.28772050e-01,  2.03345135e-01,\n",
       "        4.29135650e-01,  1.60445854e-01,  3.79414141e-01,  1.24757186e-01,\n",
       "       -1.09849334e-01, -4.55698401e-01,  1.78174138e-01, -2.14136481e-01,\n",
       "       -3.10758203e-01, -2.15668887e-01, -2.04274848e-01, -2.95817137e-01,\n",
       "        2.80361235e-01, -1.77793384e-01,  2.40966648e-01, -1.62373185e-01,\n",
       "        1.72536016e-01, -1.64124802e-01, -3.86327878e-02, -1.69407234e-01,\n",
       "        1.16910562e-01, -8.86193961e-02, -1.16494678e-01,  7.82553863e-04,\n",
       "        1.03916243e-01,  2.17620328e-01, -8.32124710e-01,  2.61193484e-01,\n",
       "       -8.11028033e-02,  2.02850178e-01,  1.35404795e-01, -1.05164750e-02,\n",
       "       -2.58429404e-02,  5.44921588e-03,  2.77866218e-02,  7.08697617e-01,\n",
       "        3.36136401e-01,  1.22152016e-01,  8.70335549e-02,  4.56405897e-03,\n",
       "        3.30118448e-01,  7.25562811e-01,  2.56263733e-01,  8.86211693e-02,\n",
       "        9.69435945e-02, -2.50822127e-01, -4.38323468e-02,  7.82862678e-02,\n",
       "        4.52800661e-01, -6.22939924e-03,  2.97666013e-01,  1.00291416e-01,\n",
       "       -3.94602790e-02, -4.74240929e-01, -2.58413851e-01, -1.84760287e-01,\n",
       "       -8.06651786e-02, -4.17714834e-01,  3.79727781e-01, -7.64747560e-02,\n",
       "       -9.89124328e-02, -3.86936255e-02,  2.14152575e-01, -1.70957386e-01,\n",
       "       -4.20120537e-01, -6.87268913e-01,  7.04723448e-02, -5.45971394e-02,\n",
       "        2.48576015e-01,  3.84492539e-02,  1.85456481e-02, -4.56262499e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sentence = model.encode('Estudando modelos de linguagem contextualizados')\n",
    "embedding_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1680118849702,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "aaIqblJZ4SGy",
    "outputId": "53569243-90f6-4fac-e242-1d005d68b86a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XUVDn_Uo4x29"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12602,
     "status": "ok",
     "timestamp": 1680119080939,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "L44i0LZT46pH",
    "outputId": "7614f024-76b8-4624-c639-7f8b528bec88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6776it [1:18:47,  1.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m y_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(df_data\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[1;32m----> 6\u001b[0m   embedding_texto \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m   X_embeddings\u001b[38;5;241m.\u001b[39mappend(embedding_texto)\n\u001b[0;32m      9\u001b[0m   y_embeddings\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    162\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 165\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    168\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     64\u001b[0m     trans_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     69\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: output_tokens, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    417\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    424\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 425\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    435\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:284\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    276\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    283\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 284\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_embeddings = []\n",
    "y_embeddings = []\n",
    "\n",
    "for idx, row in tqdm.tqdm(df_data.iterrows()):\n",
    "    \n",
    "\n",
    "    embedding_texto = np.array(model.encode(row['text_pt']))\n",
    "\n",
    "    X_embeddings.append(embedding_texto)\n",
    "    y_embeddings.append(row['label'])\n",
    "\n",
    "X_embeddings = np.array(X_embeddings)\n",
    "y_embeddings = np.array(y_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lau8c2NR5vCV"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19740,
     "status": "ok",
     "timestamp": 1680119856985,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "hENKwngj6NCW",
    "outputId": "aea014a8-7039-45f2-cc0c-a7ba4712b679"
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "num_class = df_data['label'].nunique()\n",
    "\n",
    "xgb = xgb.XGBClassifier(max_depth=4, n_estimators=1000, objective='multi:softmax', learning_rate=0.1, num_class=num_class)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=0)\n",
    "sss.get_n_splits(X_embeddings, y_embeddings)\n",
    "\n",
    "for train_index, test_index in sss.split(X_embeddings, y_embeddings):\n",
    "\n",
    "    X_train, X_test = X_embeddings[train_index], X_embeddings[test_index]\n",
    "    y_train, y_test = y_embeddings[train_index], y_embeddings[test_index] \n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, xgb.predict(X_test)))\n",
    "print(confusion_matrix(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "107bbkZr9OQA"
   },
   "source": [
    "# Abordagem Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4025,
     "status": "ok",
     "timestamp": 1680120221891,
     "user": {
      "displayName": "Túlio Ribeiro",
      "userId": "08221362987374488126"
     },
     "user_tz": 180
    },
    "id": "gmy1MXyK6YPN",
    "outputId": "084c8a6e-546a-417b-9871-aea04a1babf2"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "num_class = df_data['label'].nunique()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased',\n",
    "                                                      num_labels=num_class,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eVAI8eF9_6S"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data.index.values,\n",
    "                                                    df_data.label.values,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=df_data.label.values)\n",
    "\n",
    "df_data['data_type'] = ['not_set'] * df_data.shape[0]\n",
    "\n",
    "df_data.loc[X_train, 'data_type'] = 'train'\n",
    "df_data.loc[X_test, 'data_type'] = 'test'\n",
    "\n",
    "df_data.groupby(['sentiment', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0qIUbZh-xE0"
   },
   "outputs": [],
   "source": [
    "# embedding eh gerado dentro da arquitetura\n",
    "# sao gerados os ids dos tokens para servir de input no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iX06TzN9RxcU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "                                          \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_data[df_data.data_type=='train'].text_pt.values, \n",
    "    add_special_tokens=True, #[CLS] Sentença [SEP]\n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, #[PAD]\n",
    "    max_length=512, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    df_data[df_data.data_type=='test'].text_pt.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=512, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_data[df_data.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(df_data[df_data.data_type=='test'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-69Q6tJzRyJy"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), \n",
    "                                   batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnU0fyi7R0H0"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 10\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfnyRVmkR3AI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def f1_score_func(preds, labels, metric):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average=metric)\n",
    "\n",
    "def f1_score_func_average(preds, labels, average_f1):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average=average_f1)\n",
    "\n",
    "def accuracy_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return metrics.accuracy_score(labels_flat, preds_flat)\n",
    "\n",
    "def classification_report_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    report = metrics.classification_report(labels_flat,preds_flat)\n",
    "    print(report)\n",
    "\n",
    "def matrix_confusion_class(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    print(confusion_matrix(labels_flat,preds_flat))\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mQufmf2R3z8"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_test_total = 0\n",
    "    predictions, true_test = [], []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_test_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_test.append(label_ids)\n",
    "    \n",
    "    loss_test_avg = loss_test_total/len(dataloader_test) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_test = np.concatenate(true_test, axis=0)\n",
    "            \n",
    "    return loss_test_avg, predictions, true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEYREwO3R644"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "seed_test = 42\n",
    "random.seed(seed_test)\n",
    "np.random.seed(seed_test)\n",
    "torch.manual_seed(seed_test)\n",
    "torch.cuda.manual_seed_all(seed_test)\n",
    "device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "    \n",
    "for epoch in tqdm.tqdm(range(1, epochs+1)):   \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'/content/drive/MyDrive/UNIFOR/Tutorial BERT/fine_tuning/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    test_loss, predictions, true_test = evaluate(dataloader_test)\n",
    "    tqdm.tqdm.write(f'Test loss: {test_loss}')\n",
    "    f1_micro = f1_score_func(predictions, true_test, 'micro')\n",
    "    f1_macro = f1_score_func(predictions, true_test, 'macro')\n",
    "    f1_weighted = f1_score_func(predictions, true_test, 'weighted')\n",
    "    tqdm.tqdm.write(f'F1 Score (Micro): {f1_micro}')\n",
    "    tqdm.tqdm.write(f'F1 Score (Macro): {f1_macro}')\n",
    "    tqdm.tqdm.write(f'F1 Score (Weighted): {f1_weighted}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP0ZjS77m04HYon9GxRtKuS",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "006f5366d50640bf8b6ed1c7cbe6b780": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f761891f7c6e40208781c4730ee381cc",
      "placeholder": "​",
      "style": "IPY_MODEL_a3ed45f08d81441483b62385e4756318",
      "value": " 210k/210k [00:00&lt;00:00, 1.18MB/s]"
     }
    },
    "048585850a84404d9d046ab00e33f28f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06302fed845c48b98d26d1223173e29d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07276c1f47a94daab5ef3ff5ca0625d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a68cd2ce3334688b15e3c9a0b45ccc2",
       "IPY_MODEL_2eb30c0fee6d4159ba7dcc95c2996119",
       "IPY_MODEL_3ebc052066dd4dfdae4c6b76c317a9a0"
      ],
      "layout": "IPY_MODEL_048585850a84404d9d046ab00e33f28f"
     }
    },
    "0d26d6d3d5974d4186f8d349c9106c45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10913bb63ee24e429c40e6812d7951d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f66e81e0ad54b638508129049c2a6ae",
      "placeholder": "​",
      "style": "IPY_MODEL_ee33990fe0b246da839d06f3a234e7ea",
      "value": " 647/647 [00:00&lt;00:00, 29.2kB/s]"
     }
    },
    "15b6808d3766433b81320b576ec132e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16579a8254ec4e34a8df51a07d2f5cf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfd8282f6c7543b7a5bbe23fcf483db1",
       "IPY_MODEL_d24f39c93ea34f1687ef0de19d77146c",
       "IPY_MODEL_3ef4323c8ae24b20bfaa485426b06df3"
      ],
      "layout": "IPY_MODEL_dc473f1a937b4aceb82ba3bfb9651995"
     }
    },
    "1684697a23ac4fa4a5e36e72ad3b1dbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16b9dd32aedb4037ba8aa968442dcc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6055117171de413fb7febd123d2a9688",
      "max": 647,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ce2c1ac79d1407a8f024459d7530129",
      "value": 647
     }
    },
    "17c6874004e2421a843fb0b9133bf54e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ce2c1ac79d1407a8f024459d7530129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2039946865b34c27a1393eff4b8c9879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3df675b2b4724fc6996cb386dea4fe9a",
       "IPY_MODEL_c1e523b52bda4869b86b6b483a328884",
       "IPY_MODEL_8e3e81db27a84c7daced38043a4c7c9b"
      ],
      "layout": "IPY_MODEL_4b18c597207149dab44cfab95acf6b12"
     }
    },
    "2450423e1251433789bd9ed0c5dbfc0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28a59df9f94d478dbefc02339404599a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d5357cea5994bed90eb413bc5c8f15a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb30c0fee6d4159ba7dcc95c2996119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cc5a3663f5c48619fe44bbb774903f9",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc15c9075f374d2b899056e2f968c387",
      "value": 112
     }
    },
    "34c95de6207f481497f961b8e25dad66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34dd1390936446509a4f9f44022315a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "353d5f4692ce4224a1dd989d48b565fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3df675b2b4724fc6996cb386dea4fe9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1684697a23ac4fa4a5e36e72ad3b1dbb",
      "placeholder": "​",
      "style": "IPY_MODEL_412826b76a7b46e4a65faaa19ffe10cb",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "3ebc052066dd4dfdae4c6b76c317a9a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2450423e1251433789bd9ed0c5dbfc0c",
      "placeholder": "​",
      "style": "IPY_MODEL_4ec4090ee0674fac92ec2b8b402e45ca",
      "value": " 112/112 [00:00&lt;00:00, 1.71kB/s]"
     }
    },
    "3ef4323c8ae24b20bfaa485426b06df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_622333dbcdf94eb4922e7f60d7af98b3",
      "placeholder": "​",
      "style": "IPY_MODEL_4236c539ad6e474db83275183753602d",
      "value": " 2.00/2.00 [00:00&lt;00:00, 54.6B/s]"
     }
    },
    "412826b76a7b46e4a65faaa19ffe10cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4236c539ad6e474db83275183753602d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4452e2da0e0d454ab29feb6b46a261b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b18c597207149dab44cfab95acf6b12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cc5a3663f5c48619fe44bbb774903f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dec09a9cd2e4b3e97fca94142ac2447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ec4090ee0674fac92ec2b8b402e45ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50c69d7d18eb418fbf6623e55f2a81a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54c508e30b4241d3af3d714b36beed1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54ca153acdf343e683dc269d0ed88467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c508e30b4241d3af3d714b36beed1a",
      "placeholder": "​",
      "style": "IPY_MODEL_28a59df9f94d478dbefc02339404599a",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "5d8a5bf90cc64ff8a50b298b02e8b57a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d5357cea5994bed90eb413bc5c8f15a",
      "max": 209528,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef80ae8e193e46aa98cebdd992897c90",
      "value": 209528
     }
    },
    "5e7f1b3164a14f0f993836a3483f83fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4452e2da0e0d454ab29feb6b46a261b4",
      "max": 438235074,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5e6dc4e37de4d86a513786bd1fe10f0",
      "value": 438235074
     }
    },
    "6055117171de413fb7febd123d2a9688": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "622333dbcdf94eb4922e7f60d7af98b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65e89a54b30d46c4b85701bcdc2cd7a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c9e8b1a6ffa4a488d8b8338bb23483a",
       "IPY_MODEL_5e7f1b3164a14f0f993836a3483f83fc",
       "IPY_MODEL_9b28a10088ef461c99240b3e00d0cbed"
      ],
      "layout": "IPY_MODEL_8d818c9d71a44cb0bd0db00db228b9ef"
     }
    },
    "6c9e8b1a6ffa4a488d8b8338bb23483a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34dd1390936446509a4f9f44022315a6",
      "placeholder": "​",
      "style": "IPY_MODEL_34c95de6207f481497f961b8e25dad66",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "6ffa4859021b47daa19163c589b8bad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f66e81e0ad54b638508129049c2a6ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a68cd2ce3334688b15e3c9a0b45ccc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc0991f1e3a34482894d3e272a428b0f",
      "placeholder": "​",
      "style": "IPY_MODEL_353d5f4692ce4224a1dd989d48b565fe",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "8d818c9d71a44cb0bd0db00db228b9ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8df5a7b2f95a44888b142a75ec3fc8c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e3e81db27a84c7daced38043a4c7c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cebe9f719244064b4247b4b4a17cd7a",
      "placeholder": "​",
      "style": "IPY_MODEL_908b2a8094d940f3b69f638423f46926",
      "value": " 43.0/43.0 [00:00&lt;00:00, 647B/s]"
     }
    },
    "908b2a8094d940f3b69f638423f46926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "990de0407fef43b380a1be1e17755d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b28a10088ef461c99240b3e00d0cbed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc20a9b065274880b157c1b67342f665",
      "placeholder": "​",
      "style": "IPY_MODEL_15b6808d3766433b81320b576ec132e9",
      "value": " 438M/438M [00:04&lt;00:00, 116MB/s]"
     }
    },
    "9cebe9f719244064b4247b4b4a17cd7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d2d3e69369d43408a70e58c47efc0fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3ed45f08d81441483b62385e4756318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a86d753a0aa04115b3c71e87337a4af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc0991f1e3a34482894d3e272a428b0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc20a9b065274880b157c1b67342f665": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1e523b52bda4869b86b6b483a328884": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50c69d7d18eb418fbf6623e55f2a81a8",
      "max": 43,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a86d753a0aa04115b3c71e87337a4af1",
      "value": 43
     }
    },
    "c5e6dc4e37de4d86a513786bd1fe10f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cba2a1f38a3345078c88e036d2936ac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5d3c57dc16d49d39acbf892df9752c6",
       "IPY_MODEL_5d8a5bf90cc64ff8a50b298b02e8b57a",
       "IPY_MODEL_006f5366d50640bf8b6ed1c7cbe6b780"
      ],
      "layout": "IPY_MODEL_06302fed845c48b98d26d1223173e29d"
     }
    },
    "cc15c9075f374d2b899056e2f968c387": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfd8282f6c7543b7a5bbe23fcf483db1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dec09a9cd2e4b3e97fca94142ac2447",
      "placeholder": "​",
      "style": "IPY_MODEL_9d2d3e69369d43408a70e58c47efc0fb",
      "value": "Downloading (…)in/added_tokens.json: 100%"
     }
    },
    "d24f39c93ea34f1687ef0de19d77146c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8df5a7b2f95a44888b142a75ec3fc8c6",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ffa4859021b47daa19163c589b8bad5",
      "value": 2
     }
    },
    "dc473f1a937b4aceb82ba3bfb9651995": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5d3c57dc16d49d39acbf892df9752c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17c6874004e2421a843fb0b9133bf54e",
      "placeholder": "​",
      "style": "IPY_MODEL_990de0407fef43b380a1be1e17755d67",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "ee33990fe0b246da839d06f3a234e7ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef80ae8e193e46aa98cebdd992897c90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef8fa493c1604ca3b580c4386cf91bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54ca153acdf343e683dc269d0ed88467",
       "IPY_MODEL_16b9dd32aedb4037ba8aa968442dcc7c",
       "IPY_MODEL_10913bb63ee24e429c40e6812d7951d1"
      ],
      "layout": "IPY_MODEL_0d26d6d3d5974d4186f8d349c9106c45"
     }
    },
    "f761891f7c6e40208781c4730ee381cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
